\documentclass{article}
\usepackage[a4paper, left=15mm, top=20mm, right=15mm,bottom=20mm]{geometry}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{fancyhdr}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{float}
\usepackage{hyperref}
\usepackage{lscape}
%\usepackage{arev}

\pagestyle{fancy}
\fancyhf{}
\lhead{ST2132}
\rhead{claudeonrs}
\rfoot{\thepage}
\usepackage{amsmath, amssymb, amsfonts, listings}
\usepackage{xcolor}
\usepackage{enumitem}
\setlist{nolistsep}


%New colors defined below
\definecolor{codegreen}{rgb}{0,0.6,0.4}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{commentgreen}{rgb}{0.4,0.8,0.6}
%Code listing style named "mystyle"
\lstdefinestyle{mystyle}{
  backgroundcolor=\color{backcolour},
  commentstyle=\color{red},
  keywordstyle=\color{blue},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codegreen},
  basicstyle=\ttfamily,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=2
}

%"mystyle" code listing set
\lstset{style=mystyle}

\title{No Title}
\author{Claudeon R Susanto}
\date{}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{lmodern}

\renewcommand{\familydefault}{\sfdefault}   % Supprime le serif (dyslexie)
\usepackage[font=sf, labelfont={sf}]{caption}
\usepackage{multicol}
\usepackage{makecell}
\renewcommand\theadalign{bc}
\renewcommand\theadfont{\bfseries}
\renewcommand\theadgape{\Gape[4pt]}
\renewcommand\cellgape{\Gape[4pt]}

\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\setlength{\columnseprule}{1pt}
\begin{document}
%\maketitle
\fontfamily{lmss}\selectfont
\begin{multicols}{2}
\section{Probability Review}

\textbf{Multinomial Distribution}
$$\Pr(X_1=x_1, \dots, X_r = x_r) = {n \choose {x_1,\dots,x_r}} \prod_{i=1}^rp_i^{x_i}$$
\textbf{Mean Square Error (MSE)}
$$\text{E}\{(Y-c)^2\} = \text{var}(Y) + \{\text{E}(Y)-c\}^2$$
$$\text{E}\{(Y-c)^2|x\} = \text{var}[Y|x] + \{\text{E}[Y|x]-c\}^2$$
which are special cases of $\text{E}(Y^2) = \text{var}(Y) + [\text{E}(Y)]^2$. MSE is minimized if and only if $c=\text{E}(Y)$ or $\text{E}[Y|x]$.\\
Usually the formula for $\text{E}[Y|x]=f(x)$ is determined from observations/data and $x$ can be a vector of realisations from covariates.
$$\text{MSE}_{\text{empirical}} = \frac{1}{n}\sum_{i=1}^n\{\text{E}[Y|x_i]-y_i\}^2$$
In the real world, we have different realisations $x_i$ of the random variable $X$, hence the mean MSE is
$$\frac{1}{n}\sum_{i=1}^{n}\text{var}[Y|x_i] \approx \text{E}(\text{var}[Y|X]) \leq \text{var}(Y)$$
\textbf{Analysis of Variance (ANOVA)}\\
involves breaking of variance into components
$$\text{var}(Y) = \text{E}(\text{var}[Y|X]) + \text{var}(\text{E}[Y|X])$$

\subsection{Distributions}

\textbf{$\chi^2_1$ distribution}\\
Let $Z \sim \mathcal{N}(0,1)$. $V = Z^2$ has a $\chi^2$ distribution with 1 degree of freedom
$$f(v) = \frac{1}{\sqrt{2\pi}}v^{-1/2}e^{-v/2}$$

\textbf{Gamma distribution}
$$f(t) = \frac{\lambda^\alpha}{\Gamma(\alpha)}t^{\alpha-1}e^{-\lambda t}, t\geq 0$$
$$\Gamma(\alpha) = \int_{0}^{\infty}x^{\alpha-1}e^{-x}dx$$

\textbf{$\chi^2_n$ distribution}\\
Let $V_1,\dots,V_n$ be IID $\chi^2_1$
$$V = \sum_{i=1}^nV_i$$
has a $\chi^2_n$ distribution with $n$ degrees of freedom\\

\textbf{$t$ distribution}\\
Let $Z \sim \mathcal{N}(0,1)$ and $V \sim \chi^2_n$ be independent
$$t_n = \frac{Z}{\sqrt{V/n}}$$ has a $t$ distribution with $n$ degrees of freedom\\

\textbf{$F$ distribution}\\
Let $V \sim \chi_m^2$ and $W \sim \chi^2_n$ be independent
$$F_{m,n} = \frac{V/m}{W/n}$$ has an $F$ distribution with $(m,n)$ degrees of freedom\\
*Note: $t_n^2 = F_{1,n}$

\subsection{Sample Variance}
$$S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2$$
$$\bar{X} \text{ and } S^2 \text{ are independent}$$
$$\bar{X} \sim \mathcal{N}\left(\mu,\frac{\sigma^2}{n}\right)$$
$$\frac{(n-1)S^2}{\sigma^2}\sim \chi^2_{n-1}$$
$$\frac{\bar{X}-\mu}{S/\sqrt{n}} \sim t_{n-1}$$
\section{Survey and Random Sampling}
Let $X_1, \dots, X_N$ be random draws without replacement from a population of size $N$ with mean $\mu$ and variance $\sigma^2$.
$$\text{cov}(X_i, X_j) = -\frac{\sigma^2}{N-1} \forall i\neq j$$
$$\text{var}(\bar{X}) = \left(\frac{N-n}{N-1}\right)\frac{\sigma^2}{n}$$

\subsection{Exchangeable}
RV's $Y_1, \dots, Y_k$ are exchangeable if all reordered vectors have the same distribution as $(Y_1, \dots Y_k)$. i.e. for any permutation $\pi$ on $\{1,\dots,K\}$,
$$(Y_{\pi(1)}, \dots, Y_{\pi(k)}) \stackrel{d}{=}(Y_{1}, \dots, Y_{k})$$
\subsection{Estimate and Estimator}
$$\bar{X} = \frac{1}{n}\sum_{i=1}^{n}X_i$$
$$\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i$$
\begin{itemize}
	\item $\mu$, $\sigma$, $\sigma^2$ are \textbf{parameters}
	\item $\bar{x}$ is an \textbf{estimate} of $\mu$
	\item $\bar{x}$ is a realisation of the \textbf{estimator} $\bar{X}$
	\item \textbf{Standard Error (SE)} is defined as the SD of the estimator
	$$\text{SE} = \text{SD}(\bar{X}) = \frac{\sigma}{\sqrt{n}}$$
	which is how much $\bar{X}$ fluctuates around $\mu$
	\item Estimate of $\sigma$
	\begin{itemize}
		\item Biased estimate of $\sigma^2$
		$$\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^2$$
		$$E(\hat{\sigma}^2) = \frac{n-1}{n}\sigma^2$$
		\item Unbiased estimate of $\sigma^2$ (preferred)
		$$s^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2$$
		$$E(s^2) = \sigma^2$$
	\end{itemize}

\end{itemize}
How to estimate $\mu$?
\begin{itemize}
	\item $\mu$ is estimated by $\bar{x}$
	\item Error in $\bar{x}$ is measured by the SE: $$\text{SD}(\bar{x})=\frac{\sigma}{\sqrt{n}}$$ which is \textbf{estimated} by $\frac{s}{\sqrt{n}}$ since $\sigma$ is unknown
	\item \textbf{Conclusion}: $\mu$ is estimated as $\bar{x}$, give or take $\frac{s}{\sqrt{n}}$
	$$ \text{ SE estimated by } \frac{s}{\sqrt{n}} = \frac{\sqrt{\frac{n}{n-1}}\times \text{SD} }{\sqrt{n}}$$
	$$\text{where SD } = \hat{\sigma}$$
\end{itemize}
How to estimate $p$?
\begin{itemize}
	\item $\hat{p}$ is the estimator of $p$
	$$E(\hat{p}) = p$$
	$$\text{var}(\hat{p}) = \frac{\sigma^2}{n} = \frac{p(1-p)}{n}$$
	$$\text{SE} = \text{SD}(\hat{p}) = \sqrt{\frac{p(1-p)}{n}}$$
	which is \textbf{estimated }by realisations of $\hat{p}$
\end{itemize}
\subsection{Interval estimation}
\subsubsection{Definitions}
\begin{itemize}
	\item For sufficiently large $n$,
	$$\frac{\bar{X}-\mu}{\sigma/\sqrt{n}} \sim \mathcal{N}(0,1)$$
	\item The $p$-quantile of $Z\sim\mathcal{N}(0,1)$ is the number $q$ such that
	$$\Phi(q) = \Pr(Z\leq q) = p$$
	$$q = \Phi^{-1}(p)$$
	\begin{lstlisting}[language=R]
q <- qnorm(p)
p <- pnorm(q)\end{lstlisting}
	\item For $0 < p < 0.5$, let $z_p$ be such that
	$$\Pr(Z > z_p) = p$$
	$$z_p = \Phi^{-1}(1-p)$$

	In other words, $z_p = (1-p)$-quantile of $Z$
\subsubsection{CI Estimation}
	\item For large $n$,
	$$\bar{X} \sim \mathcal{N}\left(\mu, \frac{\sigma^2}{n}\right)$$
	$$\Pr\left(-z_{\frac{\alpha}{2}} \leq \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\leq z_{\frac{\alpha}{2}} \right) \approx 1-\alpha$$

	$$\Pr\left( \bar{X} - z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X} + z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}\right) \approx 1-\alpha$$
	where the above, $\left( \bar{X} - z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}} , \bar{X} + z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}\right)$ is a random interval. Realisation $\bar{x}$ of $\bar{X}$ gives the realised interval
	\item $(1-\alpha)$-CI for $\mu$ is of the form
	$$\left(\text{estimate} - z_{\frac{\alpha}{2}}\text{SE},\text{estimate} + z_{\frac{\alpha}{2}}\text{SE} \right)$$
\subsubsection{Exact CI}
	\item Let $t_{\frac{\alpha}{2}, n-1}$ be the number such that $$\Pr(t_{n-1} > t_{\frac{\alpha}{2}, n-1}) = \alpha/2$$
	\item \textbf{[Important]} Exact CI only works if $X \sim \mathcal{N}(\mu,\sigma^2)$ and $x_i$'s are realisations from IID \underline{Normal Distribution}\\
	* CI is exact means that $\Pr$($\mu$ is within the interval) is exactly $1-\alpha$
	\item $(1-\alpha)$-CI for $\mu$ is
	$$\left( \bar{x} - t_{\frac{\alpha}{2}, n-1}\frac{s}{\sqrt{n}},\bar{x} + t_{\frac{\alpha}{2}, n-1}\frac{s}{\sqrt{n}}\right)$$
\end{itemize}
\subsection{Bias in Survey}
Famous example: US presidential election survey conducted by \textit{Literary Digest} in 1936
\subsubsection{Bias in Measurement}
\begin{itemize}
	\item $x_1, \dots, x_n$ are realisations of random draws $X_i, \dots, X_n$ from a population with mean $\mu + b$ and variance $\sigma^2$
	\item SE $= \sigma/\sqrt{n}$ measures how far $\bar{x}$ is from $E(\bar{X}) = \mu + b$
	\item How to remove bias?
	\item MSE
	\begin{equation*}
		\begin{aligned}
			\text{E}(\bar{X}-\mu)^2 &= \text{var}(\bar{X}) + \{\text{E}(\bar{X}) - \mu\}^2\\
			\text{MSE} &= \text{SE}^2 + \text{bias}^2
		\end{aligned}
	\end{equation*}
However $\mu$ is unknowable, hence it is not possible to remove bias unless we make very careful observations
\end{itemize}

\section{Useful Results}
$$\sum_{i=1}^n(X_i-\bar{X})^2 = \sum_{i=1}^nX_i^2 - n\bar{X}^2$$
\end{multicols}






\end{document}